{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarefa Data Set Grupo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "falar do dataset??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports necessários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import sklearn as skl\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leitura e Tratamento de Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explicar o tratamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221252.60286    4939\n",
      "240000.00000      33\n",
      "192000.00000      32\n",
      "180000.00000      28\n",
      "216000.00000      20\n",
      "                ... \n",
      "93787.00000        1\n",
      "253108.00000       1\n",
      "234079.00000       1\n",
      "342373.00000       1\n",
      "874267.00000       1\n",
      "Name: duration_ms, Length: 26028, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('music_genre.csv')\n",
    "\n",
    "\n",
    "df = df.dropna(axis=0)\n",
    "\n",
    "# length of track name \n",
    "df['track_name_length'] = df['track_name'].apply(lambda x: len(x))\n",
    "\n",
    "# check if remixz in track name\n",
    "#df['isRemix'] = df['track_name'].apply(lambda x: 1 if 'remix' in x.lower() else 0)\n",
    "#print(df['isRemix'].value_counts())\n",
    "\n",
    "\n",
    "df = df.drop(['instance_id','obtained_date','artist_name','track_name'],axis=1)\n",
    "\n",
    "\n",
    "\n",
    "lb_make = LabelEncoder()\n",
    "\n",
    "# handle missing values on tempo\n",
    "df['tempo'] = df['tempo'].apply(lambda x : 0 if x == '?' else float(x))\n",
    "mean = df['tempo'].mean()\n",
    "\n",
    "#Label encoding mode\n",
    "df['mode'] = df['mode'].apply(lambda x : 1 if x == 'Major' else 0)\n",
    "df['tempo'] = df['tempo'].apply(lambda x : mean if x == 0 else float(x))\n",
    "\n",
    "#Join genre Rap and Hip-Hop\n",
    "df['music_genre'] = df['music_genre'].apply(lambda x : 'Rap' if x == 'Hip-Hop' else x)\n",
    "\n",
    "# handle missing values on duration\n",
    "mean = df['duration_ms'].mean()\n",
    "df['duration_ms'] = df['duration_ms'].apply(lambda x : mean if x == -1 else x)\n",
    "\n",
    "\n",
    "#print(df.isna().sum())\n",
    "\n",
    "#df['music_genre'] = lb_make.fit_transform(df['music_genre'])\n",
    "df['key'] = lb_make.fit_transform(df['key'])\n",
    "\n",
    "#df = df.drop(['key','music_genre'],axis=1)\n",
    "print(df['duration_ms'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def correlation(df):\n",
    "    corr_matrix = df.corr() \n",
    "    f, ax = plt.subplots(figsize=(12, 16))\n",
    "    sns.heatmap(corr_matrix, vmin=-1, vmax=1, square=True, annot=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analise de Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos de Aprendizagem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decisionTree(x,y):\n",
    "    clf = DecisionTreeClassifier(random_state=2022)\n",
    "\n",
    "    scores = cross_val_score(clf,x,y,cv=10)\n",
    "    # scores = cross_val_score(clf, x, y,  cv=10)\n",
    "    print(scores.mean())\n",
    "    print(scores)\n",
    "\n",
    "    X_train,X_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=2021)\n",
    "    clf.fit(X_train,y_train)\n",
    "\n",
    "    predictions = clf.predict(X_test)\n",
    "    print(accuracy_score(y_test, predictions))\n",
    "    #conf = confusion_matrix(y_test, predictions)\n",
    "    #df_cm = pd.DataFrame(conf, range(9), range(9))\n",
    "    ## plt.figure(figsize=(10,7))\n",
    "    #sns.heatmap(df_cm, annot=True) # font size\n",
    "    #plt.show()\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_test, predictions)\n",
    "\n",
    "    plt.clf()\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.xlabel('FPR')\n",
    "    plt.ylabel('TPR')\n",
    "    plt.title('ROC curve')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomForest(x,y):\n",
    "    clf = RandomForestClassifier(random_state=2022)\n",
    "\n",
    "    scores = cross_val_score(clf,x,y.values.ravel(),cv=5)\n",
    "    print(scores.mean())\n",
    "    print(scores)\n",
    "\n",
    "    X_train,X_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=2021)\n",
    "    clf.fit(X_train,y_train.values.ravel())\n",
    "\n",
    "    predictions = clf.predict(X_test)\n",
    "    print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vetor Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorMachine(x,y):\n",
    "    clf = SVC(random_state=2022)\n",
    "    #scores = cross_val_score(clf,x,y.values.ravel(),cv=5)\n",
    "    #print(scores.mean())\n",
    "    #print(scores)\n",
    "\n",
    "    X_train,X_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=2021)\n",
    "    clf.fit(X_train,y_train.values.ravel())\n",
    "    predictions = clf.predict(X_test)\n",
    "    print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressão Lógica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticRegression(x,y):\n",
    "    clf = LogisticRegression(random_state=2022,solver='liblinear',max_iter=1000)\n",
    "    scores = cross_val_score(clf,x,y.values.ravel(),cv=10)\n",
    "\n",
    "    print(scores.mean())\n",
    "    \n",
    "    #X_train,X_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=2021)\n",
    "    #clf.fit(X_train,y_train.values.ravel())\n",
    "    #predictions = clf.predict(X_test)\n",
    "    #print(predictions.shape)\n",
    "    #cm = confusion_matrix(y_test, predictions)\n",
    "    #print(cm)\n",
    "#\n",
    "    #cmd = ConfusionMatrixDisplay(cm, display_labels=df['music_genre'].unique())\n",
    "    #cmd.plot()\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(x,y):\n",
    "    clf = KMeans(n_clusters=9, random_state=2022)\n",
    "    scores = cross_val_score(clf,x,y.values.ravel(),cv=10)\n",
    "    print(scores.mean())\n",
    "    print(scores)\n",
    "\n",
    "    X_train,X_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=2021)\n",
    "    clf.fit(X_train,y_train.values.ravel())\n",
    "    predictions = clf.predict(X_test)\n",
    "    print(accuracy_score(y_test, predictions))\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e4232ba91af15287bb6e22f048a400c66441e65e81d515e711ee0ff9295514e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
